airflow:
  legacyCommands: false
  image:
    repository: airflow
    tag: bytewax-2.7.3
    pullPolicy: IfNotPresent
  executor: KubernetesExecutor
  fernetKey: ""  
  webserverSecretKey: ""
  config:
    #AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: "True"
    #AIRFLOW__WEBSERVER__RBAC: "True"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"    
    AIRFLOW__EMAIL__EMAIL_BACKEND: "airflow.utils.email.send_email_smtp"
    AIRFLOW__EMAIL__EMAIL_CONN_ID: "smtp_default"        
    AIRFLOW__SMTP__SMTP_HOST: "smtp.sendgrid.net"
    AIRFLOW__SMTP__SMTP_STARTTLS: "True"
    AIRFLOW__SMTP__SMTP_SSL: "False"    
    AIRFLOW__SMTP__SMTP_PORT: "587"
    
    #AIRFLOW__METRICS__STATSD_ON: false
    #AIRFLOW__METRICS__STATSD_HOST: "host.docker.internal"
    #AIRFLOW__METRICS__STATSD_PORT: "8125"
    #AIRFLOW__METRICS__STATSD_PREFIX: "airflow"
    #AIRFLOW__METRICS__STATSD_DATADOG_ENABLED: true
    #AIRFLOW__METRICS__STATSD_ALLOW_LIST: "scheduler,executor,dagrun"
    #AIRFLOW__METRICS__STATSD_DATADOG_TAGS: "statsd_group:airflow,statsd_env:pipelines"
  users:
    - username: admin
      password: ${AIRFLOW_ADMIN_PASSWORD}
      role: Admin
      email: admin@example.com
      firstName: admin
      lastName: admin    
  usersTemplates:    
    AIRFLOW_ADMIN_PASSWORD:
      kind: secret
      name: airflow
      key: airflow-admin-password    
  usersUpdate: true
  connections: []
  variables: []
  pools: [] 
  extraPipPackages: []
    #- "datadog==0.42.0"
    #- "apache-airflow[statsd]"
  extraEnv:   
    - name: AIRFLOW__CORE__FERNET_KEY
      valueFrom:
        secretKeyRef:
          name: airflow
          key: airflow-core-fernet-key
    - name: AIRFLOW__WEBSERVER__SECRET_KEY
      valueFrom:
        secretKeyRef:
          name: airflow
          key: airflow-webserver-secret-key       
    - name: KAFKA_HOST
      value: "host.docker.internal"
    - name: KAFKA_PORT
      value: "9092"
    - name: REDIS_HOST
      value: "host.docker.internal"
    - name: REDIS_PORT
      value: "6379"
    - name: REDIS_DB
      value: "0"
    - name: REDIS_PASSWORD
      valueFrom:
        secretKeyRef:
          name: airflow
          key: redis-password
    - name: POSTGRES_HOST
      value: "host.docker.internal"
    - name: POSTGRES_PORT
      value: "5432"
    - name: POSTGRES_DB
      value: "ssp"
    - name: POSTGRES_USER
      value: "some"
    - name: POSTGRES_PASSWORD
      valueFrom:
        secretKeyRef:
          name: airflow
          key: postgres-password 
    - name: CLICKHOUSE_PORT
      value: "8123"
    - name: CLICKHOUSE_DB
      value: "default"
    - name: CLICKHOUSE_HOST
      value: "host.docker.internal"
    - name: CLICKHOUSE_USER
      value: "username"
    - name: CLICKHOUSE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: airflow
          key: clickhouse-password
    - name: DB_PATH
      value: "/pipedrive/databases" 
    - name: RAW_PATH
      value: "/pipedrive/raw"
    - name: RUST_BACKTRACE
      value: "full"
    - name: GID_ROOT
      value: "https://the.gid.is"  
    - name: AIRFLOW__SMTP__SMTP_MAIL_FROM
      valueFrom:
        secretKeyRef:
          name: airflow
          key: airflow-smtp-smtp-mail-from
    - name: AIRFLOW__SMTP__SMTP_USER
      valueFrom:
        secretKeyRef:
          name: airflow
          key: airflow-smtp-smtp-user
    - name: AIRFLOW__SMTP__SMTP_PASSWORD
      valueFrom:
        secretKeyRef:
          name: airflow
          key: airflow-smtp-smtp-password
    - name: AZURE_CLIENT_ID
      valueFrom:
        secretKeyRef:
          name: airflow
          key: azure-client-id  
    - name: AZURE_CLIENT_SECRET
      valueFrom:
        secretKeyRef:
          name: airflow
          key: azure-client-secret     
    - name: AZURE_TENANT_ID
      valueFrom:
        secretKeyRef:
          name: airflow
          key: azure-tenant-id         
  extraVolumeMounts:
    - name: airflow-logs      
      mountPath: /opt/airflow/logs
    - name: airflow-sftp  
      mountPath: /opt/airflow/id_rsa
      readOnly: true
      subPath: ssh-privatekey
  extraVolumes:
    - name: airflow-logs
      persistentVolumeClaim:
        claimName: airflow-logs-pvc
    - name: airflow-sftp
      secret:
        defaultMode: 420
        secretName: airflow-ssh-sftp-secret  
  extraInitContainers: []
  kubernetesPodTemplate:
    stringOverride: ""
    resources: {}
    extraPipPackages: []      
    extraVolumeMounts: []   
    extraVolumes: [] 
    
scheduler:
  replicas: 1
  resources: {}
  extraInitContainers: []
   
  logCleanup:
    enabled: false
    retentionMinutes: 21600
  livenessProbe:
    enabled: true
    taskCreationCheck:
      enabled: true
      thresholdSeconds: 300
      schedulerAgeBeforeCheck: 180
web: 
  replicas: 1
  resources: {}
  service:
    type: ClusterIP
    externalPort: 8080
  webserverConfig:
    stringOverride: |
      from airflow import configuration as conf
      from flask_appbuilder.security.manager import AUTH_DB
      
      # the SQLAlchemy connection string
      SQLALCHEMY_DATABASE_URI = conf.get("core", "SQL_ALCHEMY_CONN")
      
      # use embedded DB for auth
      AUTH_TYPE = AUTH_DB  
    existingSecret: ""
workers:
  logCleanup:
    enabled: false  
  enabled: false
triggerer:
  enabled: true
  replicas: 1
  resources: {}
  capacity: 1000
flower:
  enabled: false
logs:  
  path: /opt/airflow/logs
  persistence:
    enabled: false
    #storageClass: "default"
    #size: 5Gi
    #accessMode: ReadWriteMany    
dags:
  path: /opt/airflow/dags
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: "git@github.com:smartdataHQ/pipelines.git"
    branch: "live_transactions_importer"
    revision: "HEAD"
    syncWait: 60    
    sshSecret: "airflow-ssh-git-secret"
    sshSecretKey: "ssh-privatekey"
    sshKnownHosts: |-
      github.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=
ingress:
  enabled: false      
serviceAccount:
  create: true
  name: ""
  annotations: {}
extraManifests: []  
pgbouncer:
  enabled: false
  resources: {}
  authType: md5
postgresql:
  enabled: false
  persistence:
    enabled: true
    storageClass: ""
    size: 8Gi
externalDatabase:
  type: postgres  
  host: host.docker.internal
  port: 5432
  database: airflow_postgres_db
  user: airflow_postgres_user  
  passwordSecret: "airflow"
  passwordSecretKey: "airflow-postgres-password"
  properties: ""
redis:  
  enabled: false
externalRedis:
  host: host.docker.internal
  port: 6379
  databaseNumber: 0
  passwordSecret: "airflow"
  passwordSecretKey: "airflow-redis-password"
